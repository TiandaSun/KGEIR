{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import spacy\n",
    "from heapq import nlargest\n",
    "from llama_index.core import PromptTemplate\n",
    "sys.path.append(os.path.abspath(\"MHQA-ontology\"))\n",
    "from prompts.prompt_templates import *\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Dict, Tuple, Union\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from utils.RAG_process import rag_generate\n",
    "from utils.RAG_process import refine_supporting_facts\n",
    "import ast\n",
    "from utils.iterative_reasoner import process_question_with_kg_awareness\n",
    "from utils.KG_builder import build_rdflib_knowledge_graph,process_contexts_in_batches\n",
    "import traceback\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = Ollama(model=\"llama3.3\", request_timeout= 600.0,keep_alive=-1)\n",
    "Hotpot_train = json.load(open('dataset/hotpot/hotpot_train_v1.1.json'))\n",
    "\n",
    "dataset_df = pd.DataFrame(Hotpot_train[:400])\n",
    "\n",
    "dataset = Hotpot_train[:15]\n",
    "dataset_df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "/mnt/scratch/users/ts1201/MHQA-ontology/utils/RAG_process.py:521: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  coverage = pd.concat([coverage, new_row], ignore_index=True)\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:utils.RAG_process:Processed 0 rows...\n",
      "INFO:utils.RAG_process:Processing complete\n"
     ]
    }
   ],
   "source": [
    "RAG_context = rag_generate(dataset,llm)\n",
    "dataset_df = pd.DataFrame(dataset)\n",
    "refine_dataset = dataset_df[dataset_df['question'].isin(RAG_context['Question'])].reset_index(drop=True)\n",
    "refined_df = refine_supporting_facts(RAG_context, RAG_context, refine_dataset)\n",
    "\n",
    "def compare_facts(refined_df):\n",
    "    \"\"\"\n",
    "    Compares if all Supporting Facts are in Retrieval Facts.\n",
    "    Sets coverage_all to 1 if all are present, else 0.\n",
    "    \"\"\"\n",
    "    df = refined_df.copy()\n",
    "    \n",
    "    # Function to check if all supporting facts are in retrieval facts\n",
    "    def check_coverage(row):\n",
    "        supporting = row['Supporting Facts']\n",
    "        retrieval = row['Retrieval Facts']\n",
    "        \n",
    "        # Convert strings to lists if needed\n",
    "        if isinstance(supporting, str):\n",
    "            supporting = ast.literal_eval(supporting)\n",
    "        if isinstance(retrieval, str):\n",
    "            retrieval = ast.literal_eval(retrieval)\n",
    "        \n",
    "        # Convert lists to strings for simple comparison\n",
    "        supporting_str = [str(item) for item in supporting]\n",
    "        retrieval_str = [str(item) for item in retrieval]\n",
    "        \n",
    "        # Check if all supporting facts are in retrieval facts\n",
    "        all_present = all(item in retrieval_str for item in supporting_str)\n",
    "        return 1 if all_present else 0\n",
    "    \n",
    "    # Apply the function to each row\n",
    "    df['coverage_all'] = df.apply(check_coverage, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "refined_df2 = compare_facts(refined_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Hotpot_train[:15]\n",
    "dataset_df = pd.DataFrame(dataset)\n",
    "RAG_context_1 = refined_df2[refined_df2['coverage_all'] == 1].reset_index(drop=True)\n",
    " \n",
    "dataset_df = dataset_df.loc[dataset_df['supporting_facts'].isin(RAG_context_1['Supporting Facts'].to_numpy())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_supporting_fact_content(supporting_facts, dataset_df):\n",
    "    \"\"\"\n",
    "    Extract text content for supporting facts from dataset_df.\n",
    "    \n",
    "    Args:\n",
    "        supporting_facts: List of supporting facts in format [[title, sentence_idx], ...]\n",
    "        dataset_df: DataFrame containing 'context' column with the 3D list structure\n",
    "    \n",
    "    Returns:\n",
    "        List of text content for each supporting fact\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Get the context data from dataset_df\n",
    "    # Since we need the corresponding row, we need to find which row has the matching context\n",
    "    for fact in supporting_facts:\n",
    "        title = fact[0]\n",
    "        sentence_idx = fact[1]\n",
    "        content_found = False\n",
    "        \n",
    "        # Search through each row in dataset_df to find matching title\n",
    "        for _, row in dataset_df.iterrows():\n",
    "            context_data = row['context']\n",
    "            \n",
    "            # Search through the context data for the title\n",
    "            for item in context_data:\n",
    "                if item[0] == title:  # Found matching title\n",
    "                    sentences = item[1]\n",
    "                    if 0 <= sentence_idx < len(sentences):\n",
    "                        results.append(sentences[sentence_idx])\n",
    "                    else:\n",
    "                        results.append(f\"[Index {sentence_idx} out of range for '{title}']\")\n",
    "                    content_found = True\n",
    "                    break\n",
    "            \n",
    "            if content_found:\n",
    "                break\n",
    "        \n",
    "        if not content_found:\n",
    "            results.append(f\"[No context found for '{title}']\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to apply to each row in RAG_context_1\n",
    "def process_row(row, dataset_df):\n",
    "    supporting_facts = row['Supporting Facts']\n",
    "    return extract_supporting_fact_content(supporting_facts, dataset_df)\n",
    "\n",
    "# Create the new column\n",
    "RAG_context_1['Supporting fact result'] = RAG_context_1.apply(\n",
    "    lambda row: process_row(row, dataset_df), axis=1\n",
    ")\n",
    "\n",
    "# Example usage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>gold_answer</th>\n",
       "      <th>Supporting Facts</th>\n",
       "      <th>SPARQL query</th>\n",
       "      <th>Retrieval Facts</th>\n",
       "      <th>Retrieval Result</th>\n",
       "      <th>coverage_all</th>\n",
       "      <th>coverage_rate</th>\n",
       "      <th>Supporting fact result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which magazine was started first Arthur's Maga...</td>\n",
       "      <td>Arthur's Magazine</td>\n",
       "      <td>[[Arthur's Magazine, 0], [First for Women, 0]]</td>\n",
       "      <td>SELECT ?magazine WHERE { Arthur's_Magazine has...</td>\n",
       "      <td>[[First for Women, 0], [Radio City (Indian rad...</td>\n",
       "      <td>[{'title': 'First for Women', 'paragraphs': ['...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>[Arthur's Magazine (1844–1846) was an American...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Oberoi family is part of a hotel company t...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>[[Oberoi family, 0], [The Oberoi Group, 0]]</td>\n",
       "      <td>SELECT ?city WHERE { The_Oberoi_Family part_of...</td>\n",
       "      <td>[[Hotel Tallcorn, 4], [Hotel Bond, 5], [Glennw...</td>\n",
       "      <td>[{'title': 'Oberoi family', 'paragraphs': ['Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>[The Oberoi family is an Indian family that is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What nationality was James Henry Miller's wife?</td>\n",
       "      <td>American</td>\n",
       "      <td>[[Peggy Seeger, 0], [Peggy Seeger, 1], [Ewan M...</td>\n",
       "      <td>SELECT ?nationality WHERE { James_Henry_Miller...</td>\n",
       "      <td>[[Incest: From a Journal of Love, 1], [Peggy S...</td>\n",
       "      <td>[{'title': 'Jim Miller (Australian footballer,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>[Margaret \"Peggy\" Seeger (born June 17, 1935) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who was once considered the best kick boxer in...</td>\n",
       "      <td>Badr Hari</td>\n",
       "      <td>[[Global Fighting Championship, 1], [Global Fi...</td>\n",
       "      <td>SELECT ?kickboxer WHERE { ?kickboxer has_profe...</td>\n",
       "      <td>[[Badr Hari, 1], [Prosecution of gender-target...</td>\n",
       "      <td>[{'title': 'Badr Hari', 'paragraphs': [' Hari ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>[ Fighters from around world on the roster inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Dutch-Belgian television series that \"Hous...</td>\n",
       "      <td>2006</td>\n",
       "      <td>[[House of Anubis, 0], [Het Huis Anubis, 1]]</td>\n",
       "      <td>SELECT ?firstAirYear WHERE { House_of_Anubis i...</td>\n",
       "      <td>[[Batibot, 7], [Batibot, 6], [Het Huis Anubis,...</td>\n",
       "      <td>[{'title': 'House of Anubis', 'paragraphs': ['...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.377358</td>\n",
       "      <td>[House of Anubis is a mystery television serie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fast Cars, Danger, Fire and Knives includes gu...</td>\n",
       "      <td>Jaime Meline</td>\n",
       "      <td>[[Fast Cars, Danger, Fire and Knives, 2], [El-...</td>\n",
       "      <td>SELECT ?executive WHERE { Fast_Cars_Danger_Fir...</td>\n",
       "      <td>[[El-P, 0], [Changes (Alyson Avenue album), 2]...</td>\n",
       "      <td>[{'title': 'Fast Cars, Danger, Fire and Knives...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>[ Vocals are handled by Aesop Rock, with guest...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question        gold_answer  \\\n",
       "0  Which magazine was started first Arthur's Maga...  Arthur's Magazine   \n",
       "1  The Oberoi family is part of a hotel company t...              Delhi   \n",
       "2    What nationality was James Henry Miller's wife?           American   \n",
       "3  Who was once considered the best kick boxer in...          Badr Hari   \n",
       "4  The Dutch-Belgian television series that \"Hous...               2006   \n",
       "5  Fast Cars, Danger, Fire and Knives includes gu...       Jaime Meline   \n",
       "\n",
       "                                    Supporting Facts  \\\n",
       "0     [[Arthur's Magazine, 0], [First for Women, 0]]   \n",
       "1        [[Oberoi family, 0], [The Oberoi Group, 0]]   \n",
       "2  [[Peggy Seeger, 0], [Peggy Seeger, 1], [Ewan M...   \n",
       "3  [[Global Fighting Championship, 1], [Global Fi...   \n",
       "4       [[House of Anubis, 0], [Het Huis Anubis, 1]]   \n",
       "5  [[Fast Cars, Danger, Fire and Knives, 2], [El-...   \n",
       "\n",
       "                                        SPARQL query  \\\n",
       "0  SELECT ?magazine WHERE { Arthur's_Magazine has...   \n",
       "1  SELECT ?city WHERE { The_Oberoi_Family part_of...   \n",
       "2  SELECT ?nationality WHERE { James_Henry_Miller...   \n",
       "3  SELECT ?kickboxer WHERE { ?kickboxer has_profe...   \n",
       "4  SELECT ?firstAirYear WHERE { House_of_Anubis i...   \n",
       "5  SELECT ?executive WHERE { Fast_Cars_Danger_Fir...   \n",
       "\n",
       "                                     Retrieval Facts  \\\n",
       "0  [[First for Women, 0], [Radio City (Indian rad...   \n",
       "1  [[Hotel Tallcorn, 4], [Hotel Bond, 5], [Glennw...   \n",
       "2  [[Incest: From a Journal of Love, 1], [Peggy S...   \n",
       "3  [[Badr Hari, 1], [Prosecution of gender-target...   \n",
       "4  [[Batibot, 7], [Batibot, 6], [Het Huis Anubis,...   \n",
       "5  [[El-P, 0], [Changes (Alyson Avenue album), 2]...   \n",
       "\n",
       "                                    Retrieval Result  coverage_all  \\\n",
       "0  [{'title': 'First for Women', 'paragraphs': ['...             1   \n",
       "1  [{'title': 'Oberoi family', 'paragraphs': ['Th...             1   \n",
       "2  [{'title': 'Jim Miller (Australian footballer,...             1   \n",
       "3  [{'title': 'Badr Hari', 'paragraphs': [' Hari ...             1   \n",
       "4  [{'title': 'House of Anubis', 'paragraphs': ['...             1   \n",
       "5  [{'title': 'Fast Cars, Danger, Fire and Knives...             1   \n",
       "\n",
       "   coverage_rate                             Supporting fact result  \n",
       "0       0.152174  [Arthur's Magazine (1844–1846) was an American...  \n",
       "1       0.282051  [The Oberoi family is an Indian family that is...  \n",
       "2       0.478261  [Margaret \"Peggy\" Seeger (born June 17, 1935) ...  \n",
       "3       0.375000  [ Fighters from around world on the roster inc...  \n",
       "4       0.377358  [House of Anubis is a mystery television serie...  \n",
       "5       0.285714  [ Vocals are handled by Aesop Rock, with guest...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAG_context_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "result_set = []\n",
    "\n",
    "# Process each item in RAG_context_1\n",
    "for i in range(len(RAG_context_1)):\n",
    "    start_time = datetime.now()\n",
    "    question = RAG_context_1['Question'][i]\n",
    "    \n",
    "    try:\n",
    "        all_facts = RAG_context_1['Retrieval Result'][i]\n",
    "        context_data = RAG_context_1['Retrieval Result'][i]\n",
    "        \n",
    "        # Process knowledge graph\n",
    "        knowledge_graph = process_contexts_in_batches(\n",
    "            context_items=all_facts,\n",
    "            llm=llm,\n",
    "            prompt_template=prompt_template_context,\n",
    "            batch_size=2  # Process 2 contexts at a time\n",
    "        )\n",
    "        \n",
    "        kg = build_rdflib_knowledge_graph(knowledge_graph)\n",
    "        kg.serialize('kg'+str(i,format='ttl')\n",
    "        \n",
    "    except Exception as e:\n",
    "        # If error occurs, create a result dict with None values except for question\n",
    "        error_result = {\n",
    "            \"question\": question,\n",
    "            \"answer\": None,\n",
    "            \"queries_tried\": None,\n",
    "            \"kg_exploration\": None,\n",
    "            \"evidence_source\": None,\n",
    "            \"confidence\": None,\n",
    "            \"full_response_for_final\": None\n",
    "        }\n",
    "        result_set.append(error_result)\n",
    "        \n",
    "        # Print error information for debugging\n",
    "        print(f\"Error processing question {i}: {str(e)}\")\n",
    "        print(traceback.format_exc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
